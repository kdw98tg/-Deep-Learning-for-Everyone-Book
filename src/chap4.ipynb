{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05a32af7",
   "metadata": {},
   "source": [
    "# 4. 가장 훌륭한 예측선\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee0f29",
   "metadata": {},
   "source": [
    "## 선형 회귀\n",
    "- '가장 훌륭한 예측선' 이라는 표현은 `선형 회귀`분석을 이용한 모델의 의미를 쉽게 풀어서 표현한것임\n",
    "- 선을 잘 그어놓으면 지금 안보이는 먼 미래의 데이터도 예측할 수 있음\n",
    "- y=ax 그래프도 어떤값을 대입해도 값을 예측할 수 있는것과 같음\n",
    "- y=ax에서 x에 따라 y의 값이 바뀜\n",
    "- 독립적으로 변할 수 있는 값인 x를 `독립변수`, 그에 따라 변하는 y가 `종속변수임`\n",
    "- 하나의 x값만으로도 y값을 설명할 수 있다면, `단순 선형 회귀` x값이 여러개가 필요하다면 `다중 선형 회귀임`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe9a4e9",
   "metadata": {},
   "source": [
    "## 파이썬 코딩으로 확인하는 최소 제곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2156f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f073f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 준비\n",
    "# 넘파이 배열로 만들거임임\n",
    "x = np.array([2,4,6,8]) # 공부한 시간\n",
    "y = np.array([81,93,91,97]) #그에따른 점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "135091a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x 평균 5.0\n",
      "y 평균 90.5\n"
     ]
    }
   ],
   "source": [
    "# x의 평균값을 구함\n",
    "mx = np.mean(x)# x 의 평균\n",
    "my = np.mean(y)# y 의 평균\n",
    "\n",
    "print(\"x 평균\", mx)\n",
    "print(\"y 평균\", my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38bece60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분모 : 20.0\n",
      "분자 : 46.0\n"
     ]
    }
   ],
   "source": [
    "# 기울기 공식의 분모와 분자\n",
    "\n",
    "# 분모부분\n",
    "divisor = sum([(i - mx)**2 for i in x])\n",
    "\n",
    "# 분자부분\n",
    "def top(x, mx, y ,my):\n",
    "    d = 0\n",
    "    for i in range(len(x)):\n",
    "        d += (x[i] - mx) * (y[i] - my)\n",
    "    return d\n",
    "\n",
    "dividend = top (x, my, y, my)\n",
    "\n",
    "#출력으로 확인하기\n",
    "print(\"분모 :\", divisor)\n",
    "print(\"분자 :\" , dividend)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49f5c85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기울기 :  2.3\n",
      "절편 :  79.0\n"
     ]
    }
   ],
   "source": [
    "# 기울기와 절편 구하기\n",
    "\n",
    "# 기울기 a를 구하는 공식\n",
    "a = dividend / divisor\n",
    "\n",
    "# y절편 구하기\n",
    "b = my - (mx * a)\n",
    "\n",
    "print(\"기울기 : \", a)\n",
    "print(\"절편 : \", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72aaa7f",
   "metadata": {},
   "source": [
    "## 평균 제곱 오차\n",
    "- 최소 제곱법은 데이터가 적을수록 좋은데, 데이터가 17개 이렇게 되면 계산량이 엄청 많아짐\n",
    "- 그래서 최소 제곱법보다는 `일단 조금씩 수정해 나가기` 기법을 많이 씀\n",
    "- 가설을 하나 세운 후 이 값이 주어진 요건을 충족하는지 판단해서 조금씩 변화를 주고, 이 변화가 긍적적이면 오차가 최소가 될때까지 이과정을 반복함\n",
    "- **이는 딥러닝을 가능하게 하는 가장 중요한 원리 중 하나임**\n",
    "- 가상의 a, b 값을 설정하고, 그래프를 그림\n",
    "- 그리고 실제 데이터랑 얼마나 떨어져있는가를 절대값을 씌워서 더함\n",
    "- 그 값이 작을수록 최적화된 모델인것임임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c903b701",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_a = 3 # 임의의 기울기 \n",
    "fake_b = 76 # 임의의 절편\n",
    "\n",
    "\n",
    "#공부 시간 x와 성적 y의 넘파이 배열을 만듭니다.\n",
    "x = np.array([2, 4, 6, 8])\n",
    "y = np.array([81, 93, 91, 97]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "784c2cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공부시간=2, 실제점수=81, 예측점수=82\n",
      "공부시간=4, 실제점수=93, 예측점수=88\n",
      "공부시간=6, 실제점수=91, 예측점수=94\n",
      "공부시간=8, 실제점수=97, 예측점수=100\n"
     ]
    }
   ],
   "source": [
    "# 평균 제곱 오차 구하기\n",
    "\n",
    "# y = ax + b에 가상의 a,b 값을 대입한 결과를 출력하는 함수\n",
    "def predict(x):\n",
    "    return fake_a * x + fake_b\n",
    "\n",
    "# 예측 값이 들어갈 빈 리스트를 만듦\n",
    "predict_result = []\n",
    "\n",
    "# 모든 x값을 한 번씩 대입하여 predict_result 리스트를 완성함\n",
    "for i in range(len(x)):\n",
    "    predict_result.append(predict(x[i]))\n",
    "    print(\"공부시간=%.f, 실제점수=%.f, 예측점수=%.f\" % (x[i], y[i], predict(x[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84403288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 제곱 오차 : 11.0\n"
     ]
    }
   ],
   "source": [
    "# 평균 제곱 오차 함수를 각 y값에 대입하여 최종 값을 구함\n",
    "n = len(x)\n",
    "def mse(y, y_pred):\n",
    "    return (1/n) * sum((y - y_pred)**2)\n",
    "\n",
    "# 평균 제곱 오차 값을 출력함\n",
    "print(\"평균 제곱 오차 : \"+ str(mse(y,predict_result)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
